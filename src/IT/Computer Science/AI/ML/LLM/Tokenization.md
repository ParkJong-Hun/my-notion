# Tokenization

<aside>
💡

토큰화.
AI 모델이 텍스트를 처리하기 위해 작은 단위로 나누는 과정.

단어, 단어의 일부분, 문자를 토큰으로 변환.

</aside>